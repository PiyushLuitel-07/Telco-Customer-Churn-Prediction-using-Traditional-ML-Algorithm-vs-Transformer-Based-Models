{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045954f3",
   "metadata": {},
   "source": [
    "# ðŸ“Š Customer Churn Prediction Report: Transformer vs Random Forest (Evaluation and Recommendation)\n",
    "\n",
    "## ðŸ“ Dataset Summary\n",
    "\n",
    "- **Binary Target Variable**: Churn (Yes/No)\n",
    "- **Class Imbalance**: Slight imbalance â†’ handled using **SMOTE**\n",
    "- **Gender Distribution**: Equal distribution (Male â‰ˆ Female)\n",
    "- **Outliers**: No outliers detected in continuous variables (via boxplots)\n",
    "- **Correlation**: \n",
    "  - `MonthlyCharges` and `TotalCharges` â†’ positively correlated.\n",
    "  - Customers with higher `MonthlyCharges` tend to **churn more**.\n",
    "- **Tenure Insights**:\n",
    "  - Churn is **very high during the first year**.\n",
    "  - Very **low churn** beyond 4 years â†’ indicates customer **loyalty increases with tenure**.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  Model 1: Transformer-Based Model (TabTransformer)\n",
    "\n",
    "### âš™ï¸ Architecture Overview\n",
    "- Utilizes **self-attention layers** to capture dependencies among categorical features.\n",
    "- Categorical features are **embedded** into dense vectors.\n",
    "- These embeddings are **processed by Transformer blocks** (multi-head attention + feed-forward layers).\n",
    "- Outputs are concatenated with normalized numerical features and passed through an MLP head.\n",
    "- Trained using `Binary Cross-Entropy Loss` with the `Adam` optimizer.\n",
    "\n",
    "### ðŸ“ˆ Performance\n",
    "| Metric         | Class 0 (No) | Class 1 (Yes) |\n",
    "|----------------|-------------|---------------|\n",
    "| Precision      | 0.83        | 0.66          |\n",
    "| Recall         | 0.91        | 0.50          |\n",
    "| F1-Score       | 0.87        | 0.57          |\n",
    "\n",
    "- **Accuracy**: 0.80  \n",
    "- **Macro F1**: 0.72  \n",
    "- **Weighted F1**: 0.79  \n",
    "- **ROC AUC Score**: 0.8156 âœ…\n",
    "\n",
    "> ðŸ”Ž **Observations**:  \n",
    "> - **Strong overall accuracy and precision**, especially for class 0 (non-churners).\n",
    "> - Shows **significant improvement** in recall for churners ( **0.50**).\n",
    "> - ROC AUC of **0.82** indicates good separation capability.\n",
    "> - Still underperforms in detecting churners compared to Random Forest.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŒ² Model 2: Random Forest Classifier\n",
    "\n",
    "### âš™ï¸ Config\n",
    "```python\n",
    "RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    max_features='log2',\n",
    "    min_samples_leaf=2,\n",
    "    n_estimators=200,\n",
    "    random_state=0\n",
    ")\n",
    "```\n",
    "\n",
    "### ðŸ“ˆ Performance\n",
    "| Metric         | Class 0 (No) | Class 1 (Yes) |\n",
    "|----------------|-------------|---------------|\n",
    "| Precision      | 0.89        | 0.54          |\n",
    "| Recall         | 0.77        | 0.72          |\n",
    "| F1-Score       | 0.83        | 0.62          |\n",
    "\n",
    "- **Accuracy**: 0.76  \n",
    "- **Macro F1**: 0.72  \n",
    "- **Weighted F1**: 0.77  \n",
    "\n",
    "> ðŸ”Ž **Observations**:  \n",
    "> - Slightly **lower overall accuracy** than Transformer (0.76 vs 0.80)\n",
    "> - **Highest recall for churners (0.72)** among all models â€” critical for identifying at-risk customers.\n",
    "> - More balanced F1 scores for both classes.\n",
    "> - Offers interpretability through feature importance.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ” Feature Importance from Random Forest\n",
    "\n",
    "| Rank | Feature                            | Importance |\n",
    "|------|------------------------------------|------------|\n",
    "| 1    | `tenure`                           | 0.1361     |\n",
    "| 2    | `PaymentMethod_Electronic check`   | 0.1081     |\n",
    "| 3    | `TotalCharges`                     | 0.1077     |\n",
    "| 4    | `MonthlyCharges`                   | 0.0988     |\n",
    "| 5    | `InternetService_Fiber optic`      | 0.0981     |\n",
    "| 6    | `tenure_range`                     | 0.0866     |\n",
    "| 7    | `Contract_Two year`                | 0.0802     |\n",
    "\n",
    "> ðŸ“Œ Key Insight:\n",
    "> - **Tenure** is the top predictive feature â€” matches EDA findings.\n",
    "> - Features like **payment method** and **monthly charges** significantly impact churn probability.\n",
    "\n",
    "---\n",
    "\n",
    "## âœ… Recommendation\n",
    "\n",
    "While both models perform well, the **Random Forest** model remains the **preferred choice** for churn prediction:\n",
    "\n",
    "### âœ” Why Random Forest?\n",
    "- **Higher recall (0.72) for churners** â€” crucial for preventing revenue loss.\n",
    "- Balanced performance with interpretability.\n",
    "- Useful for **feature importance analysis** to inform business strategies.\n",
    "\n",
    "### âš ï¸ Considerations for Transformer:\n",
    "- Better overall accuracy, but still **lags behind in identifying churners** effectively.\n",
    "\n",
    "> ðŸ“ **Final Verdict**:  \n",
    "> For a churn prediction task, **recall for the positive class (churn)** is most important.  \n",
    "> **Random Forest** provides a **better trade-off** between recall, interpretability, and real-world utility.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5d7c8d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
